import streamlit as st
from langchain.document_loaders import SitemapLoader
from langchain.document_transformers import Html2TextTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler
from langchain.schema import BaseOutputParser, output_parser
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.runnable import RunnableLambda
import re
llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.1)

answers_prompt = ChatPromptTemplate.from_template(
    """
    Using ONLY the following context answer the user's question. If you can't just say you don't know, don't make anything up.
                                                  
    Then, give a score to the answer between 0 and 5 (ex:4.7).

    If the answer answers the user question the score should be high, else it should be low.

    Make sure to always include the answer's score even if it's 0.

    Context: {context}
                                                  
    Examples:
                                                  
    Question: How far away is the moon?
    Answer: The moon is 384,400 km away.
    Score: 4.8
                                                  
    Question: How far away is the sun?
    Answer: I don't know
    Score: 0.0
                                                  
    Your turn!

    Question: {question}
"""
)

choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            Use ONLY the following pre-existing answers to answer the user's question.

            Use the answers that have the highest score (more helpful) and favor the most recent ones.

            Cite sources and return the sources of the answers as they are, do not change them.

            Answers: {answers}
            """,
        ),
        ("human", "{question}"),
    ]
)

st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸŒ",
    layout="wide",
)

html2text_transformer = Html2TextTransformer()

def parse_page(soup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    elif footer:
        footer.decompose()
    return str(soup.get_text()).replace("\n", " ").replace("\xa0", " ")


def extract_score(text):
    match = re.search(r"Score:\s*([0-5](?:\.\d+)?)", text)
    return float(match.group(1)) if match else 0.0

def get_answer(inputs):
    question = inputs["question"]
    docs = inputs["docs"]

    answer_chain = answers_prompt | llm
    answers = []
    

    for doc in docs:
        try:
       
            content = doc.page_content
            result = answer_chain.invoke({"context": content, "question": question})
            score = extract_score(result.content)
            answers.append({
                "answer": result.content,
                "source": doc.metadata.get("source", "Unknown"),
                "date": doc.metadata.get("lastmod", "Unknown"),
                "score": score
            })
        except Exception as e:
            st.warning(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return {"question": question, "answer": answers}

def choose_answer(inputs):
    question = inputs['question']
    answers = inputs['answer']
    choose_chain = choose_prompt | llm
    condensed_answer = '\n\n'.join(
        f"{answer['answer']}\nSource: {answer['source']}\nDate: {answer['date']}\nScore: {answer['score']}\n\n"
        for answer in answers
    )
    return choose_chain.invoke({'answers': condensed_answer, 'question': question})

@st.cache_resource(show_spinner="Loading sitemap...", ttl=3600)
def load_sitemap(url):
    import urllib3
    import requests
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    # SSL ê²€ì¦ì„ ì™„ì „íˆ ë¹„í™œì„±í™”í•˜ëŠ” ì„¸ì…˜ ìƒì„±
    session = requests.Session()
    session.verify = False
    
    # ì–´ëŒ‘í„° ì„¤ì •
    adapter = HTTPAdapter()
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=100)

    
    loader = SitemapLoader(
        url,
        filter_urls=[
          r"^(.*\/ai-gateway\/).*",
          r"^(.*\/vectorize\/).*", 
          r"^(.*\/workers-ai\/).*"
        ],
        parsing_function=parse_page,
        session=session
    )
    loader.requests_per_second = 10  # ì†ë„ ì¡°ì ˆ
    docs = loader.load()
    split_docs = text_splitter.split_documents(docs)
    vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    return vectorstore.as_retriever()

st.title("SiteGPT")
st.write("Cloudflare AI ì œí’ˆ ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ")

with st.sidebar:
    st.write("Cloudflare ê³µì‹ ë¬¸ì„œ")
    url = "https://developers.cloudflare.com/sitemap-0.xml"
    st.info(f"ğŸ“„ ì‚¬ì´íŠ¸ë§µ: {url}")

if url:
    if url.endswith(".xml"):
        if st.button("ğŸ”„ ë‹¤ì‹œ ë¡œë“œ", key="reload_button"):
            st.cache_data.clear()
        
        try:
            retriever = load_sitemap(url)
            query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="query")
            if query:       
                # ë¬¸ì„œ ê²€ìƒ‰ - ëª¨ë“  ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
                docs = retriever.invoke(query)
                
                chain = (
                    {
                        "docs": lambda x: docs,
                        "question": RunnablePassthrough(),
                    }
                    | RunnableLambda(get_answer)
                    | RunnableLambda(choose_answer)
                )
                result = chain.invoke({"question": query})
                st.write("**ë‹µë³€:**")
                st.write(result.content)
        except Exception as e:
            st.error(f"âŒ ì‚¬ì´íŠ¸ë§µ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    else:
        with st.sidebar:
            st.error("Please enter a Sitemap URL.")
else:
    st.markdown("""# Cloudflare AI ì œí’ˆ ë¬¸ì„œ
                 
ì´ ì‹œìŠ¤í…œì€ Cloudflareì˜ AI Gateway, Vectorize, Workers AI ì œí’ˆì— ëŒ€í•œ ì§ˆë¬¸ì„ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **AI Gateway**: AI ëª¨ë¸ API í†µí•© ë° ê´€ë¦¬
- **Vectorize**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë° ì„ë² ë”© ì„œë¹„ìŠ¤  
- **Workers AI**: ì„œë²„ë¦¬ìŠ¤ AI ì¶”ë¡  ì„œë¹„ìŠ¤

Cloudflare ê³µì‹ ë¬¸ì„œê°€ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                 
""")





