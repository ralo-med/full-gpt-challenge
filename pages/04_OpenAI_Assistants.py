#!/usr/bin/env python3
import os, json, warnings, time
from typing import Dict, List, Any, Tuple

import streamlit as st
from openai import OpenAI, InternalServerError
from requests.exceptions import RequestException

from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_community.document_loaders import WebBaseLoader

from utils import setup_sidebar, save_settings_to_session

warnings.filterwarnings(
    "ignore",
    message=r"This package \(`duckduckgo_search`\) has been renamed to `ddgs`!",
    category=RuntimeWarning,
)

os.environ.setdefault(
    "USER_AGENT",
    (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0 Safari/537.36"
    ),
)


def wiki_search(inputs: Dict[str, Any]) -> str:
    return WikipediaAPIWrapper().run(inputs["query"])

def ddg_search(inputs: Dict[str, Any]) -> str:
    wrapper = DuckDuckGoSearchAPIWrapper(safesearch="off")
    return wrapper.run(inputs["query"])

def fetch_webpage(inputs: Dict[str, Any]) -> str:
    url = inputs["url"]
    try:
        loader = WebBaseLoader(
            url,
            requests_kwargs={
                "timeout": 15,
                "headers": {"User-Agent": os.environ["USER_AGENT"]},
            },
        )
        docs = loader.load()
    except RequestException as e:
        return f"[SKIPPED] {url} ({e.__class__.__name__}: {e})"
    content = "\n\n".join(doc.page_content for doc in docs)
    cleaned = "\n".join(line.strip() for line in content.splitlines() if line.strip())
    return cleaned if cleaned else f"[EMPTY] {url}"

def save_to_file(inputs: Dict[str, Any]) -> str:
    try:
        content = inputs.get("content", "")
        if not content:
            return "ì˜¤ë¥˜: ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        with open("result.txt", "w", encoding="utf-8") as f:
            f.write(content)
        if os.path.exists("result.txt"):
            file_size = os.path.getsize("result.txt")
            return f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: result.txt ({file_size} ë°”ì´íŠ¸)\n\nğŸ¯ [ìµœì¢… ì—°êµ¬ ìš”ì•½]\n{content}"
        else:
            return "ì˜¤ë¥˜: íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}"

functions_map = {
    "wiki_search": wiki_search,
    "ddg_search": ddg_search,
    "fetch_webpage": fetch_webpage,
    "save_to_file": save_to_file,
}


tools = [
    {
        "name": "wiki_search",
        "type": "function",
        "description": "Return a concise summary from Wikipedia for the query.",
        "parameters": {
            "type": "object",
            "properties": {"query": {"type": "string"}},
            "required": ["query"],
            "additionalProperties": False,
        },
    },
    {
        "name": "ddg_search",
        "type": "function",
        "description": "Return DuckDuckGo text search results for the query.",
        "parameters": {
            "type": "object",
            "properties": {"query": {"type": "string"}},
            "required": ["query"],
            "additionalProperties": False,
        },
    },
    {
        "name": "fetch_webpage",
        "type": "function",
        "description": "Download and return raw textual content from a webpage URL.",
        "parameters": {
            "type": "object",
            "properties": {"url": {"type": "string", "format": "uri"}},
            "required": ["url"],
            "additionalProperties": False,
        },
    },
    {
        "name": "save_to_file",
        "type": "function",
        "description": "Save provided text to result.txt on disk.",
        "parameters": {
            "type": "object",
            "properties": {"content": {"type": "string"}},
            "required": ["content"],
            "additionalProperties": False,
        },
    },
]

SYSTEM_PROMPT = (
    "You are an investigative research assistant. You MUST follow this EXACT 4-step process:\n"
    "1. ALWAYS start with wiki_search to get basic information\n"
    "2. ALWAYS use ddg_search to find additional web sources\n" 
    "3. ALWAYS use fetch_webpage to extract content from at least one web page\n"
    "4. ALWAYS finish with save_to_file to save all findings\n\n"
    "CRITICAL: You MUST call save_to_file as the final step before providing your answer.\n"
    "For save_to_file, combine ALL the information you gathered from the previous steps into a comprehensive summary.\n"
    "Include the original question, findings from Wikipedia, web search results, and webpage content.\n"
    "You cannot skip any of these steps. Each tool must be used at least once in this order.\n"
    "DO NOT provide your final answer until you have called save_to_file.\n"
    "After save_to_file, provide a comprehensive final answer.\n\n"
    "MANDATORY: You are NOT allowed to finish without calling save_to_file. This is a requirement, not a suggestion.\n"
    "If you try to provide a final answer without calling save_to_file, you will be forced to call it first.\n"
    "The save_to_file function is MANDATORY and must be called before any final response."
)


def safe_create_responses(client: OpenAI, **kwargs):
    delay = 1.0
    for attempt in range(3):
        try:
            return client.responses.create(**kwargs)
        except InternalServerError:
            if attempt == 2:
                raise
            time.sleep(delay)
            delay *= 2


def render_progress_steps(progress_steps: List[Any], placeholder=None):
    """ì§„í–‰ ë‹¨ê³„ë“¤ì„ UIì— ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜"""
    container = placeholder.container() if placeholder else st
    for step in progress_steps:
        if isinstance(step, dict) and step.get("type") == "result_dropdown":
            with container.expander(f"ğŸ“„ ë‹¨ê³„ {step['step']} ê²°ê³¼ - {step['tool_name']} ({step['tool']})"):
                st.write(f"**ì‚¬ìš© ë„êµ¬**: {step['tool']}")
                st.write(f"**ë„êµ¬ ì„¤ëª…**: {step['tool_name']}")
                st.write("**ê²°ê³¼**:")
                st.text(step['result'])
        elif "ğŸ” **ë‹¨ê³„" in step:
            container.info(step)
        elif "âœ… **ë‹¨ê³„" in step:
            container.success(step)
        elif "ğŸ‰ **ì—°êµ¬ ì™„ë£Œ**" in step:
            container.success(step)
        elif "ğŸ¤” AI assistant" in step:
            container.info(step)
        else:
            container.write(step)


def research_assistant_streaming(
    client: OpenAI,
    user_msg: str,
    history: List[Dict[str, Any]],
    progress_placeholder,
    model_name: str,
) -> Tuple[List[Dict[str, Any]], str]:
    history.append({"role": "user", "content": user_msg})

    st.session_state.progress_steps = []
    progress_steps = st.session_state.progress_steps
    required_tools = {"wiki_search": False, "ddg_search": False, "fetch_webpage": False}
    save_completed = False
    final_summary = ""

    progress_steps.append("ğŸ¤” AI assistant ë¶„ì„ ì‹œì‘...")
    render_progress_steps(progress_steps, progress_placeholder)

    resp = safe_create_responses(
        client,
        model=model_name,
        input=history,
        tools=tools,
    )

    step_count = 0
    while resp.output and resp.output[0].type == "function_call" and not save_completed:
        step_count += 1
        call = resp.output[0]
        tool_descriptions = {
            "wiki_search": "ğŸ“š ìœ„í‚¤ë°±ê³¼ ê²€ìƒ‰",
            "ddg_search": "ğŸ” DuckDuckGo ì›¹ ê²€ìƒ‰", 
            "fetch_webpage": "ğŸŒ ì›¹í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ",
            "save_to_file": "ğŸ’¾ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"
        }
        tool_name = tool_descriptions.get(call.name, 'ë„êµ¬ ì‹¤í–‰ ì¤‘')
        progress_steps.append(f"ğŸ” **ë‹¨ê³„ {step_count}** {tool_name} ì¤‘...")
        result = functions_map[call.name](json.loads(call.arguments))
        if call.name in required_tools:
            required_tools[call.name] = True
        if call.name == "save_to_file":
            save_completed = True
            try:
                args = json.loads(call.arguments)
                final_summary = args.get("content", "")
            except Exception:
                final_summary = ""

        progress_steps.append(f"âœ… **ë‹¨ê³„ {step_count} ì™„ë£Œ**: {tool_name}")
        progress_steps.append({
            "type": "result_dropdown",
            "step": step_count,
            "tool": call.name,
            "tool_name": tool_name,
            "result": result
        })
        render_progress_steps(progress_steps, progress_placeholder)
        
        history.extend(
            [
                call,
                {
                    "type": "function_call_output",
                    "call_id": call.call_id,
                    "output": result,
                },
            ]
        )
        
        if save_completed:
            progress_steps.append("ğŸ‰ **ì—°êµ¬ ì™„ë£Œ**: íŒŒì¼ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            render_progress_steps(progress_steps, progress_placeholder)
            break
        if not save_completed:
            progress_steps.append("ğŸ¤” AI assistant ë„êµ¬ ì„ íƒ ì¤‘...")
            render_progress_steps(progress_steps, progress_placeholder)
        resp = safe_create_responses(
            client,
            model=model_name,
            input=history,
            tools=tools,
        )

    # ìµœì¢… ë‹µë³€: resp.output_text(assistant ë‹µë³€) ë˜ëŠ” summary(í˜¹ì‹œ output_textê°€ ë¹„ì–´ìˆì„ ë•Œ)
    final_answer = resp.output_text.strip() if resp.output_text and resp.output_text.strip() else f"ğŸ¯ [ìµœì¢… ì—°êµ¬ ìš”ì•½]\n{final_summary}"
    return history, final_answer


st.set_page_config(
    page_title="ResearchGPT",
    page_icon="ğŸ”",
    layout="wide",
)

st.title("ResearchGPT ğŸ”")
st.markdown("""
ì›¹ ê²€ìƒ‰ê³¼ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ê¸°ëŠ¥:**
- ğŸ“š ìœ„í‚¤ë°±ê³¼ ê²€ìƒ‰
- ğŸ” DuckDuckGo ì›¹ ê²€ìƒ‰
- ğŸŒ ì›¹í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ
- ğŸ’¾ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
- â­ï¸ ì €ì¥ì´ ì´ë£¨ì–´ ì§€ì§€ ì•Šì„ì‹œ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì€ê²ƒì´ë‹ˆ ê³„ì† ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©´ ë©ë‹ˆë‹¤!

""")

with st.sidebar:
    st.header("ì„¤ì •")
    api_key, model_name, temperature = setup_sidebar()
    if api_key:
        save_settings_to_session(api_key, model_name, temperature)
        os.environ["OPENAI_API_KEY"] = api_key
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()


    st.header("ğŸ“ ì €ì¥ëœ íŒŒì¼")
    if os.path.exists("result.txt"):
        try:
            with open("result.txt", "r", encoding="utf-8") as f:
                file_content = f.read()
            st.success("âœ… result.txt ì €ì¥ ì™„ë£Œ")
            st.write(f"**íŒŒì¼ í¬ê¸°:** {len(file_content)} ë¬¸ì")
            st.download_button(
                label="ğŸ“¥ result.txt ë‹¤ìš´ë¡œë“œ",
                data=file_content,
                file_name="result.txt",
                mime="text/plain"
            )
            if st.button("ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ", disabled=st.session_state.get("processing", False)):
                os.remove("result.txt")
                st.success("íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
    else:
        st.info("ğŸ“ ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.write("AIê°€ ë¶„ì„ í›„ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.")

client = None
if st.session_state.get("api_key"):
    try:
        client = OpenAI(api_key=st.session_state.get("api_key"))
    except Exception as e:
        st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
else:
    st.warning("â—ï¸ OpenAI API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if "history" not in st.session_state:
    st.session_state.history = [{"role": "system", "content": SYSTEM_PROMPT}]
if "messages" not in st.session_state:
    st.session_state.messages = []
if not isinstance(st.session_state.messages, list):
    st.session_state.messages = []
st.session_state.messages = [
    m for m in st.session_state.messages 
    if m.get("content", "").strip() and m.get("role") in ["user", "assistant"]
]


for m in st.session_state.messages:
    content = m.get("content", "")
    if content and content.strip():
        with st.chat_message(m["role"]):
            if m["role"] == "assistant" and "progress_steps" in m:
                render_progress_steps(m["progress_steps"])
            st.markdown(content)


if "processing" not in st.session_state:
    st.session_state.processing = False

if prompt := st.chat_input("ì›¹ì—ì„œ ë¬´ì—‡ì„ ì°¾ì•„ë³¼ê¹Œìš”?", disabled=st.session_state.processing):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.processing = True
    st.rerun()

if st.session_state.processing and len(st.session_state.messages) > 0 and st.session_state.messages[-1]["role"] == "user":
    user_prompt = st.session_state.messages[-1]["content"]
    with st.chat_message("assistant"):
        if client is None:
            error_message = "âŒ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            st.session_state.messages.append({"role": "assistant", "content": error_message})
            st.session_state.processing = False
            st.rerun()
        else:
            progress_placeholder = st.empty()
            try:
                st.session_state.history, answer = research_assistant_streaming(
                    client, user_prompt, st.session_state.history, progress_placeholder, model_name
                )
                
                final_message = {
                    "role": "assistant", 
                    "content": answer, 
                    "progress_steps": st.session_state.get("progress_steps", [])
                }
                st.session_state.messages.append(final_message)
                
                st.session_state.processing = False
                st.session_state.progress_steps = []
                st.rerun()

            except Exception as e:
                progress_placeholder.empty()
                error_message = f"âŒ ì—°êµ¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nğŸ’¡ API í‚¤ì™€ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.session_state.messages.append({"role": "assistant", "content": error_message})
                st.session_state.processing = False
                st.rerun()


if st.sidebar.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", disabled=st.session_state.get("processing", False)):
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.session_state.history = [{"role": "system", "content": SYSTEM_PROMPT}]
    st.session_state.messages = []
    st.session_state.progress_steps = []
    st.success("âœ… ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    st.rerun()
